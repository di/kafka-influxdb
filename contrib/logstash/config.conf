input
{
  kafka
  {
    zk_connect => "zk:2181"
    consumer_id => "Logstash_Benchmark"
    topic_id => "metrics"
    auto_offset_reset => "smallest"
    group_id => "Benchmark"
    reset_beginning => true
    consumer_threads => 1
    consumer_restart_sleep_ms => 60000
    codec => "plain"
  }
}
filter
{
  metrics
  {
    meter => "events"
    add_tag => "metric"
  }
  grok
  {
    pattern => [ '^(?<metric_name>[^\s]*?) (?<value>[^\s]+?) (?<time>\d+)$']
  }
}
output
{
  if "metric" in [tags]
  {
    stdout
    {
      codec => line
      {
        format => "rate: %{[events][count]}"
      }
    }
  }
  else
  {
    influxdb
    {
      host => "influxdb"
      port => "8086"
      db => "metrics"
      retention_policy => "default"
      user => "root"
      password => "root"
      allow_measurement_override => true
      data_points =>
      {
        "measurement" => "%{[metric_name]}"
        "time" => "%{[time]}"
        "value" => "%{[value]}"
      }
      allow_time_override => true
      time_precision => "s"
      coerce_values =>
      {
        "time" => "integer"
      }
      flush_size => "1000"
      idle_flush_time => "1"
     }
     #	stdout { codec => rubydebug }
  }
}
